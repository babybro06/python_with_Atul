{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to webpage you want to scrape\n",
    "2. Right click and select Inspect (on Chrome)\n",
    "3. Look through the hierarchy of tags in HTML (In the insepct section) of which you want data scraped\n",
    "    A. identify class names or id names of the section where data is\n",
    "4. Access the webpage in python using requests library\n",
    "5. use Beautiful soup library search and extract the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## \n",
    "import requests\n",
    "\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "\n",
    "page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Here is some simple content for this page.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Step1 declare object of a class\n",
    "soup=BeautifulSoup(page.content)\n",
    "#step2 apply data and methods\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>Here is some simple content for this page.</p>]\n"
     ]
    }
   ],
   "source": [
    "res1=soup.find_all('p')\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"tombstone-container\">\n",
      " <p class=\"period-name\">\n",
      "  This\n",
      "  <br/>\n",
      "  Afternoon\n",
      " </p>\n",
      " <p>\n",
      "  <img alt=\"This Afternoon: Partly sunny, with a high near 58. South southwest wind around 5 mph becoming light and variable. \" class=\"forecast-icon\" src=\"newimages/medium/bkn.png\" title=\"This Afternoon: Partly sunny, with a high near 58. South southwest wind around 5 mph becoming light and variable. \"/>\n",
      " </p>\n",
      " <p class=\"short-desc\">\n",
      "  Partly Sunny\n",
      " </p>\n",
      " <p class=\"temp temp-high\">\n",
      "  High: 58 °F\n",
      " </p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "#Step1: get the website using requests library\n",
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\")\n",
    "#pass the webpage to soup object\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#find section in webpage where information is available\n",
    "seven_day = soup.find(id=\"seven-day-forecast\")\n",
    "#seven_day\n",
    "\n",
    "#find section with each period info\n",
    "# forecast_items is a list\n",
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThisAfternoon\n",
      "Partly Sunny\n",
      "High: 58 °F\n"
     ]
    }
   ],
   "source": [
    "#lets process single period forecast\n",
    "tonight = forecast_items[0]\n",
    "#print(tonight.prettify())\n",
    "period = tonight.find(class_=\"period-name\").get_text()\n",
    "short_desc = tonight.find(class_=\"short-desc\").get_text()\n",
    "temp = tonight.find(class_=\"temp\").get_text()\n",
    "print(period)\n",
    "print(short_desc)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThisAfternoon\n",
      "Partly Sunny\n",
      "High: 58 °F\n",
      "-------\n",
      "Tonight\n",
      "Chance Rain\n",
      "Low: 46 °F\n",
      "-------\n",
      "Monday\n",
      "Chance Rainthen MostlySunny\n",
      "High: 57 °F\n",
      "-------\n",
      "MondayNight\n",
      "Mostly Clear\n",
      "Low: 41 °F\n",
      "-------\n",
      "Tuesday\n",
      "Sunny\n",
      "High: 57 °F\n",
      "-------\n",
      "TuesdayNight\n",
      "Partly Cloudy\n",
      "Low: 42 °F\n",
      "-------\n",
      "Wednesday\n",
      "Mostly Cloudythen SlightChance Rain\n",
      "High: 55 °F\n",
      "-------\n",
      "WednesdayNight\n",
      "Chance Rain\n",
      "Low: 46 °F\n",
      "-------\n",
      "Thursday\n",
      "Slight ChanceRain thenMostly Sunny\n",
      "High: 57 °F\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for tonight in forecast_items:\n",
    "    period = tonight.find(class_=\"period-name\").get_text()\n",
    "    short_desc = tonight.find(class_=\"short-desc\").get_text()\n",
    "    temp = tonight.find(class_=\"temp\").get_text()\n",
    "    print(period)\n",
    "    print(short_desc)\n",
    "    print(temp)\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASCII_SPACES', 'DEFAULT_BUILDER_FEATURES', 'NO_PARSER_SPECIFIED_WARNING', 'ROOT_TAG_NAME', '__bool__', '__call__', '__class__', '__contains__', '__copy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '__weakref__', '_all_strings', '_check_markup_is_url', '_feed', '_find_all', '_find_one', '_is_xml', '_lastRecursiveChild', '_last_descendant', '_linkage_fixer', '_most_recent_element', '_namespaces', '_popToTag', '_should_pretty_print', 'append', 'attrs', 'builder', 'can_be_empty_element', 'cdata_list_attributes', 'childGenerator', 'children', 'clear', 'contains_replacement_characters', 'contents', 'currentTag', 'current_data', 'declared_html_encoding', 'decode', 'decode_contents', 'decompose', 'descendants', 'element_classes', 'encode', 'encode_contents', 'endData', 'extend', 'extract', 'fetchNextSiblings', 'fetchParents', 'fetchPrevious', 'fetchPreviousSiblings', 'find', 'findAll', 'findAllNext', 'findAllPrevious', 'findChild', 'findChildren', 'findNext', 'findNextSibling', 'findNextSiblings', 'findParent', 'findParents', 'findPrevious', 'findPreviousSibling', 'findPreviousSiblings', 'find_all', 'find_all_next', 'find_all_previous', 'find_next', 'find_next_sibling', 'find_next_siblings', 'find_parent', 'find_parents', 'find_previous', 'find_previous_sibling', 'find_previous_siblings', 'format_string', 'formatter_for_name', 'get', 'getText', 'get_attribute_list', 'get_text', 'handle_data', 'handle_endtag', 'handle_starttag', 'has_attr', 'has_key', 'hidden', 'index', 'insert', 'insert_after', 'insert_before', 'isSelfClosing', 'is_empty_element', 'is_xml', 'known_xml', 'markup', 'name', 'namespace', 'new_string', 'new_tag', 'next', 'nextGenerator', 'nextSibling', 'nextSiblingGenerator', 'next_element', 'next_elements', 'next_sibling', 'next_siblings', 'object_was_parsed', 'original_encoding', 'parent', 'parentGenerator', 'parents', 'parse_only', 'parserClass', 'parser_class', 'popTag', 'prefix', 'preserve_whitespace_tag_stack', 'preserve_whitespace_tags', 'prettify', 'previous', 'previousGenerator', 'previousSibling', 'previousSiblingGenerator', 'previous_element', 'previous_elements', 'previous_sibling', 'previous_siblings', 'pushTag', 'recursiveChildGenerator', 'renderContents', 'replaceWith', 'replaceWithChildren', 'replace_with', 'replace_with_children', 'reset', 'select', 'select_one', 'setup', 'smooth', 'string', 'strings', 'stripped_strings', 'tagStack', 'text', 'unwrap', 'wrap']\n"
     ]
    }
   ],
   "source": [
    "print(dir(soup))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
